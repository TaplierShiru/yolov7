{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5380cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorrt as trt\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict,namedtuple\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c757e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = '/path/to/model/yolov7.trt'\n",
    "device = torch.device('cuda:0')\n",
    "batch_size = 16\n",
    "cap = cv2.VideoCapture('/path/to/video.mp4')\n",
    "# Or you could load image via \n",
    "# img = cv2.imread('/path/to/image.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a95dfc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, img = cap.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4b88ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880ebae0",
   "metadata": {},
   "source": [
    "# For static batch size and input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b36d0f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infer TensorRT Engine\n",
    "Binding = namedtuple('Binding', ('name', 'dtype', 'shape', 'data', 'ptr'))\n",
    "logger = trt.Logger(trt.Logger.INFO)\n",
    "trt.init_libnvinfer_plugins(logger, namespace=\"\")\n",
    "with open(w, 'rb') as f, trt.Runtime(logger) as runtime:\n",
    "    model = runtime.deserialize_cuda_engine(f.read())\n",
    "bindings = OrderedDict()\n",
    "for index in range(model.num_bindings):\n",
    "    name = model.get_binding_name(index)\n",
    "    dtype = trt.nptype(model.get_binding_dtype(index))\n",
    "    shape = tuple(model.get_binding_shape(index))\n",
    "    data = torch.from_numpy(np.empty(shape, dtype=np.dtype(dtype))).to(device)\n",
    "    bindings[name] = Binding(name, dtype, shape, data, int(data.data_ptr()))\n",
    "binding_addrs = OrderedDict((n, d.ptr) for n, d in bindings.items())\n",
    "context = model.create_execution_context()\n",
    "\n",
    "\n",
    "def letterbox(im, new_shape=(640, 640), color=(114, 114, 114), auto=True, scaleup=True, stride=32):\n",
    "    # Resize and pad image while meeting stride-multiple constraints\n",
    "    shape = im.shape[:2]  # current shape [height, width]\n",
    "    if isinstance(new_shape, int):\n",
    "        new_shape = (new_shape, new_shape)\n",
    "\n",
    "    # Scale ratio (new / old)\n",
    "    r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])\n",
    "    if not scaleup:  # only scale down, do not scale up (for better val mAP)\n",
    "        r = min(r, 1.0)\n",
    "\n",
    "    # Compute padding\n",
    "    new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))\n",
    "    dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  # wh padding\n",
    "\n",
    "    if auto:  # minimum rectangle\n",
    "        dw, dh = np.mod(dw, stride), np.mod(dh, stride)  # wh padding\n",
    "\n",
    "    dw /= 2  # divide padding into 2 sides\n",
    "    dh /= 2\n",
    "\n",
    "    if shape[::-1] != new_unpad:  # resize\n",
    "        im = cv2.resize(im, new_unpad, interpolation=cv2.INTER_LINEAR)\n",
    "    top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))\n",
    "    left, right = int(round(dw - 0.1)), int(round(dw + 0.1))\n",
    "    im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)  # add border\n",
    "    return im, r, (dw, dh)\n",
    "\n",
    "def postprocess(boxes,r,dwdh):\n",
    "    dwdh = torch.tensor(dwdh*2).to(boxes.device)\n",
    "    boxes -= dwdh\n",
    "    boxes /= r\n",
    "    return boxes\n",
    "\n",
    "names = [ 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "         'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "         'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',\n",
    "         'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',\n",
    "         'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "         'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\n",
    "         'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "         'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',\n",
    "         'hair drier', 'toothbrush' ]\n",
    "colors = {name:[random.randint(0, 255) for _ in range(3)] for i,name in enumerate(names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1193992b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3, 640, 640]), 0.3333333333333333, (0.0, 140.0))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "image = img.copy()\n",
    "or_h, or_w, _ = image.shape\n",
    "target_h, target_w = 640, 640\n",
    "image, ratio, dwdh = letterbox(image, (target_h, target_w), auto=False)\n",
    "image = image.transpose((2, 0, 1))\n",
    "image = np.expand_dims(image, 0)\n",
    "image = np.concatenate([image] * batch_size, axis=0)\n",
    "image = np.ascontiguousarray(image)\n",
    "\n",
    "im = image.astype(np.float32)\n",
    "im = torch.from_numpy(im).to(device)\n",
    "im/=255\n",
    "im.shape, ratio, dwdh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b79506",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_batch = 2\n",
    "\n",
    "# warmup for 10 times\n",
    "for _ in range(10):\n",
    "    tmp = torch.randn(batch_size,3,target_h,target_w).to(device)\n",
    "    binding_addrs['images'] = int(tmp.data_ptr())\n",
    "    context.execute_v2(list(binding_addrs.values()))\n",
    "\n",
    "start = time.perf_counter()\n",
    "binding_addrs['images'] = int(im.data_ptr())\n",
    "context.execute_v2(list(binding_addrs.values()))\n",
    "print(f'Cost {time.perf_counter()-start} s')\n",
    "\n",
    "nums = bindings['num_dets'].data\n",
    "boxes = bindings['det_boxes'].data\n",
    "scores = bindings['det_scores'].data\n",
    "classes = bindings['det_classes'].data\n",
    "nums.shape,boxes.shape,scores.shape,classes.shape\n",
    "\n",
    "boxes = boxes[i_batch,:nums[i_batch][0]]\n",
    "scores = scores[i_batch,:nums[i_batch][0]]\n",
    "classes = classes[i_batch,:nums[i_batch][0]]\n",
    "\n",
    "for box,score,cl in zip(boxes,scores,classes):\n",
    "    box = postprocess(box,ratio,dwdh).round().int()\n",
    "    name = names[cl]\n",
    "    color = colors[name]\n",
    "    name += ' ' + str(round(float(score),3))\n",
    "    cv2.rectangle(img,box[:2].tolist(),box[2:].tolist(),color,2)\n",
    "    cv2.putText(img,name,(int(box[0]), int(box[1]) - 2),cv2.FONT_HERSHEY_SIMPLEX,0.75,color,thickness=2)\n",
    "\n",
    "Image.fromarray(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a370f52f",
   "metadata": {},
   "source": [
    "## Below for dynamic batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2831be81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infer TensorRT Engine\n",
    "logger = trt.Logger(trt.Logger.INFO)\n",
    "trt.init_libnvinfer_plugins(logger, namespace=\"\")\n",
    "with open(w, 'rb') as f, trt.Runtime(logger) as runtime:\n",
    "    model = runtime.deserialize_cuda_engine(f.read())\n",
    "context = model.create_execution_context()\n",
    "\n",
    "def getBindings(model,context,shape=(1,3,640,640)):\n",
    "    context.set_binding_shape(0, shape)\n",
    "    bindings = OrderedDict()\n",
    "    Binding = namedtuple('Binding', ('name', 'dtype', 'shape', 'data', 'ptr'))\n",
    "    \n",
    "    for index in range(model.num_bindings):\n",
    "        name = model.get_binding_name(index)\n",
    "        dtype = trt.nptype(model.get_binding_dtype(index))\n",
    "        shape = tuple(context.get_binding_shape(index))\n",
    "        data = torch.from_numpy(np.empty(shape, dtype=np.dtype(dtype))).to(device)\n",
    "        bindings[name] = Binding(name, dtype, shape, data, int(data.data_ptr()))\n",
    "    return bindings\n",
    "\n",
    "def letterbox(im, new_shape=(640, 640), color=(114, 114, 114), auto=True, scaleup=True, stride=32):\n",
    "    # Resize and pad image while meeting stride-multiple constraints\n",
    "    shape = im.shape[:2]  # current shape [height, width]\n",
    "    if isinstance(new_shape, int):\n",
    "        new_shape = (new_shape, new_shape)\n",
    "\n",
    "    # Scale ratio (new / old)\n",
    "    r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])\n",
    "    if not scaleup:  # only scale down, do not scale up (for better val mAP)\n",
    "        r = min(r, 1.0)\n",
    "\n",
    "    # Compute padding\n",
    "    new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))\n",
    "    dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  # wh padding\n",
    "\n",
    "    if auto:  # minimum rectangle\n",
    "        dw, dh = np.mod(dw, stride), np.mod(dh, stride)  # wh padding\n",
    "\n",
    "    dw /= 2  # divide padding into 2 sides\n",
    "    dh /= 2\n",
    "\n",
    "    if shape[::-1] != new_unpad:  # resize\n",
    "        im = cv2.resize(im, new_unpad, interpolation=cv2.INTER_LINEAR)\n",
    "    top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))\n",
    "    left, right = int(round(dw - 0.1)), int(round(dw + 0.1))\n",
    "    im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)  # add border\n",
    "    return im, r, (dw, dh)\n",
    "\n",
    "def postprocess(boxes,r,dwdh):\n",
    "    dwdh = torch.tensor(dwdh*2).to(boxes.device)\n",
    "    boxes -= dwdh\n",
    "    boxes /= r\n",
    "    return boxes\n",
    "\n",
    "names = [ 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "         'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "         'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',\n",
    "         'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',\n",
    "         'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "         'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\n",
    "         'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "         'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',\n",
    "         'hair drier', 'toothbrush' ]\n",
    "colors = {name:[random.randint(0, 255) for _ in range(3)] for i,name in enumerate(names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fddc16da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 3, 640, 640]), 0.3333333333333333, (0.0, 140.0))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "image = img.copy()\n",
    "target_h, target_w = 640, 640\n",
    "image, ratio, dwdh = letterbox(image, auto=False)\n",
    "image = image.transpose((2, 0, 1))\n",
    "image = np.expand_dims(image, 0)\n",
    "image = np.concatenate([image] * batch_size, axis=0)\n",
    "image = np.ascontiguousarray(image)\n",
    "\n",
    "im = image.astype(np.float32)\n",
    "im = torch.from_numpy(im).to(device)\n",
    "im/=255\n",
    "im.shape, ratio, dwdh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bc50512a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# warmup for 10 times\n",
    "bindings = getBindings(model,context,(batch_size,3,target_h, target_w))\n",
    "binding_addrs = OrderedDict((n, d.ptr) for n, d in bindings.items())\n",
    "for _ in range(10):\n",
    "    tmp = torch.randn(batch_size,3,target_h, target_w).to(device)\n",
    "    binding_addrs['images'] = int(tmp.data_ptr())\n",
    "    context.execute_v2(list(binding_addrs.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6904bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bindings = getBindings(model,context,(batch_size,3,target_h, target_w))\n",
    "binding_addrs = OrderedDict((n, d.ptr) for n, d in bindings.items())\n",
    "\n",
    "start = time.perf_counter()\n",
    "binding_addrs['images'] = int(im.data_ptr())\n",
    "context.execute_v2(list(binding_addrs.values()))\n",
    "print(f'Cost {time.perf_counter()-start} s')\n",
    "\n",
    "nums = bindings['num_dets'].data\n",
    "boxes = bindings['det_boxes'].data\n",
    "scores = bindings['det_scores'].data\n",
    "classes = bindings['det_classes'].data\n",
    "\n",
    "i_batch = 0\n",
    "\n",
    "boxes = boxes[i_batch,:nums[i_batch][0]]\n",
    "scores = scores[i_batch,:nums[i_batch][0]]\n",
    "classes = classes[i_batch,:nums[i_batch][0]]\n",
    "\n",
    "for box,score,cl in zip(boxes,scores,classes):\n",
    "    box = postprocess(box,ratio,dwdh).round().int()\n",
    "    name = names[cl]\n",
    "    color = colors[name]\n",
    "    name += ' ' + str(round(float(score),3))\n",
    "    cv2.rectangle(img,box[:2].tolist(),box[2:].tolist(),color,2)\n",
    "    cv2.putText(img,name,(int(box[0]), int(box[1]) - 2),cv2.FONT_HERSHEY_SIMPLEX,0.75,color,thickness=2)\n",
    "\n",
    "Image.fromarray(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27461aac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13fa3c64",
   "metadata": {},
   "source": [
    "### Dynamic batch and image size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a34d5f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infer TensorRT Engine\n",
    "logger = trt.Logger(trt.Logger.INFO)\n",
    "trt.init_libnvinfer_plugins(logger, namespace=\"\")\n",
    "with open(w, 'rb') as f, trt.Runtime(logger) as runtime:\n",
    "    model = runtime.deserialize_cuda_engine(f.read())\n",
    "context = model.create_execution_context()\n",
    "\n",
    "def getBindings(model,context,shape=(1,3,640,640)):\n",
    "    context.set_binding_shape(0, shape)\n",
    "    bindings = OrderedDict()\n",
    "    Binding = namedtuple('Binding', ('name', 'dtype', 'shape', 'data', 'ptr'))\n",
    "    \n",
    "    for index in range(model.num_bindings):\n",
    "        name = model.get_binding_name(index)\n",
    "        dtype = trt.nptype(model.get_binding_dtype(index))\n",
    "        shape = tuple(context.get_binding_shape(index))\n",
    "        print(name, shape)\n",
    "        data = torch.from_numpy(np.empty(shape, dtype=np.dtype(dtype))).to(device)\n",
    "        bindings[name] = Binding(name, dtype, shape, data, int(data.data_ptr()))\n",
    "    return bindings\n",
    "\n",
    "def letterbox(im, new_shape=(640, 640), color=(114, 114, 114), auto=True, scaleup=True, stride=32):\n",
    "    # Resize and pad image while meeting stride-multiple constraints\n",
    "    shape = im.shape[:2]  # current shape [height, width]\n",
    "    if isinstance(new_shape, int):\n",
    "        new_shape = (new_shape, new_shape)\n",
    "\n",
    "    # Scale ratio (new / old)\n",
    "    r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])\n",
    "    if not scaleup:  # only scale down, do not scale up (for better val mAP)\n",
    "        r = min(r, 1.0)\n",
    "\n",
    "    # Compute padding\n",
    "    new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))\n",
    "    dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  # wh padding\n",
    "\n",
    "    if auto:  # minimum rectangle\n",
    "        dw, dh = np.mod(dw, stride), np.mod(dh, stride)  # wh padding\n",
    "\n",
    "    dw /= 2  # divide padding into 2 sides\n",
    "    dh /= 2\n",
    "\n",
    "    if shape[::-1] != new_unpad:  # resize\n",
    "        im = cv2.resize(im, new_unpad, interpolation=cv2.INTER_LINEAR)\n",
    "    top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))\n",
    "    left, right = int(round(dw - 0.1)), int(round(dw + 0.1))\n",
    "    im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)  # add border\n",
    "    return im, r, (dw, dh)\n",
    "\n",
    "def postprocess(boxes,r,dwdh):\n",
    "    dwdh = torch.tensor(dwdh*2).to(boxes.device)\n",
    "    boxes -= dwdh\n",
    "    boxes /= r\n",
    "    return boxes\n",
    "\n",
    "names = [ 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "         'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "         'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',\n",
    "         'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',\n",
    "         'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "         'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\n",
    "         'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "         'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',\n",
    "         'hair drier', 'toothbrush' ]\n",
    "colors = {name:[random.randint(0, 255) for _ in range(3)] for i,name in enumerate(names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "079b9970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 1080, 1920])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here example where preprocess is inside model, so we could put full image (1920x1080) into the model\n",
    "# If its not your case - uncomment line with letterbox\n",
    "\n",
    "image_for_plot = img.copy()\n",
    "image = cv2.cvtColor(image_for_plot.copy(), cv2.COLOR_BGR2RGB)\n",
    "#image, ratio, dwdh = letterbox(image, auto=False)\n",
    "image = image.transpose((2, 0, 1))\n",
    "image = np.expand_dims(image, 0)\n",
    "image = np.concatenate([image] * batch_size, axis=0)\n",
    "image = np.ascontiguousarray(image)\n",
    "\n",
    "im = image.astype(np.float32)\n",
    "im = torch.from_numpy(im).to(device)\n",
    "im/=255\n",
    "h,w = im.shape[-2:]\n",
    "im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48febbaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images (4, 3, 1080, 1920)\n",
      "num_dets (4, 1)\n",
      "det_scores (4, 100)\n",
      "det_classes (4, 100)\n",
      "det_boxes (4, 100, 4)\n"
     ]
    }
   ],
   "source": [
    "# warmup for 10 times\n",
    "bindings = getBindings(model,context,(batch_size, 3, h, w))\n",
    "binding_addrs = OrderedDict((n, d.ptr) for n, d in bindings.items())\n",
    "for _ in range(10):\n",
    "    tmp = torch.randn(batch_size, 3, h, w).to(device)\n",
    "    binding_addrs['images'] = int(tmp.data_ptr())\n",
    "    context.execute_v2(list(binding_addrs.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59054ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "bindings = getBindings(model,context,(batch_size,3, h,w))\n",
    "binding_addrs = OrderedDict((n, d.ptr) for n, d in bindings.items())\n",
    "\n",
    "start = time.perf_counter()\n",
    "binding_addrs['images'] = int(im.data_ptr())\n",
    "context.execute_v2(list(binding_addrs.values()))\n",
    "print(f'Cost {time.perf_counter()-start} s')\n",
    "\n",
    "nums = bindings['num_dets'].data\n",
    "boxes = bindings['det_boxes'].data\n",
    "scores = bindings['det_scores'].data\n",
    "classes = bindings['det_classes'].data\n",
    "\n",
    "i_batch = 0\n",
    "\n",
    "boxes = boxes[i_batch,:nums[i_batch][0]]\n",
    "scores = scores[i_batch,:nums[i_batch][0]]\n",
    "classes = classes[i_batch,:nums[i_batch][0]]\n",
    "\n",
    "for box,score,cl in zip(boxes,scores,classes):\n",
    "    box = box.round().int()\n",
    "    name = names[cl]\n",
    "    color = colors[name]\n",
    "    name += ' ' + str(round(float(score),3))\n",
    "    cv2.rectangle(image_for_plot,box[:2].tolist(),box[2:].tolist(),color,2)\n",
    "    cv2.putText(image_for_plot,name,(int(box[0]), int(box[1]) - 2),cv2.FONT_HERSHEY_SIMPLEX,0.75,color,thickness=2)\n",
    "\n",
    "Image.fromarray(image_for_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ad882f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
